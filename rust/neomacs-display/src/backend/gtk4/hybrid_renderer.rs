//! Hybrid GSK renderer - renders directly from FrameGlyphBuffer.
//!
//! This bypasses the scene graph and builds GSK nodes directly from
//! the glyph buffer, matching Emacs's immediate-mode redisplay model.
//!
//! Uses cosmic-text for text rendering (pure Rust, no Pango).
//!
//! Enable logging with: RUST_LOG=neomacs_display::backend::gtk4::hybrid_renderer=debug

use gtk4::prelude::*;
use gtk4::{gdk, gsk, graphene};
use log::{debug, trace, warn};

use crate::core::frame_glyphs::{FrameGlyph, FrameGlyphBuffer};
use crate::core::types::Color;
use crate::core::face::{Face, FaceCache};
use crate::text::{TextEngine, GlyphAtlas, GlyphKey, CachedGlyph};
use super::video::VideoCache;
use super::image::ImageCache;

/// Hybrid renderer that builds GSK nodes directly from FrameGlyphBuffer.
/// Uses cosmic-text for text rendering instead of Pango.
pub struct HybridRenderer {
    /// cosmic-text engine for text shaping and rasterization
    text_engine: TextEngine,
    /// Glyph texture atlas for caching
    glyph_atlas: GlyphAtlas,
    /// Face cache for styling
    face_cache: FaceCache,
}

impl Default for HybridRenderer {
    fn default() -> Self {
        Self::new()
    }
}

impl HybridRenderer {
    pub fn new() -> Self {
        Self {
            text_engine: TextEngine::new(),
            glyph_atlas: GlyphAtlas::new(),
            face_cache: FaceCache::new(),
        }
    }

    /// Get mutable face cache
    pub fn face_cache_mut(&mut self) -> &mut FaceCache {
        &mut self.face_cache
    }

    /// Get or rasterize a glyph, returning a cached texture
    fn get_or_rasterize_glyph(
        &mut self,
        c: char,
        face_id: u32,
        fg: &Color,
    ) -> Option<&CachedGlyph> {
        let key = GlyphKey {
            charcode: c as u32,
            face_id,
        };

        // Check cache first
        if self.glyph_atlas.contains(&key) {
            return self.glyph_atlas.get(&key);
        }

        debug!("Rasterizing '{}' (face_id={}, fg={:?})", c, face_id, fg);

        // Need to rasterize - create a temporary face with the foreground color
        let face = Face {
            id: face_id,
            foreground: *fg,
            background: Color::TRANSPARENT,
            underline_color: None,
            overline_color: None,
            strike_through_color: None,
            box_color: None,
            font_family: "monospace".to_string(),
            font_size: 13.0,
            font_weight: 400,
            attributes: crate::core::face::FaceAttributes::empty(),
            underline_style: crate::core::face::UnderlineStyle::None,
            box_type: crate::core::face::BoxType::None,
            box_line_width: 0,
        };

        // Rasterize the character
        if let Some((width, height, pixels, bearing_x, bearing_y)) =
            self.text_engine.rasterize_char(c, Some(&face))
        {
            warn!("Rasterized '{}': {}x{} bearing=({},{}) pixels_len={}", c, width, height, bearing_x, bearing_y, pixels.len());
            // Sample some pixel data to verify - find max alpha
            let max_alpha = pixels.chunks(4).map(|c| c[3]).max().unwrap_or(0);
            let non_zero_count = pixels.chunks(4).filter(|c| c[3] > 0).count();
            warn!("  max_alpha={} non_zero_alpha_pixels={}", max_alpha, non_zero_count);
            // Create GPU texture
            if let Some(texture) = TextEngine::create_texture(width, height, &pixels) {
                warn!("Created texture for '{}' size={}x{}", c, texture.width(), texture.height());
                self.glyph_atlas.insert_texture(
                    key.clone(),
                    texture,
                    width,
                    height,
                    bearing_x,
                    bearing_y,
                );
                return self.glyph_atlas.get(&key);
            } else {
                warn!("Failed to create texture for '{}'", c);
            }
        } else {
            warn!("Failed to rasterize '{}'", c);
        }

        None
    }

    /// Build GSK render nodes from FrameGlyphBuffer
    pub fn build_render_node(
        &mut self,
        buffer: &FrameGlyphBuffer,
        mut video_cache: Option<&mut VideoCache>,
        _image_cache: Option<&mut ImageCache>,
    ) -> Option<gsk::RenderNode> {
        // Update ALL video players FIRST before any rendering
        // This ensures bus polling doesn't happen during the render loop
        #[cfg(feature = "video")]
        if let Some(ref mut cache) = video_cache {
            cache.update_all();
        }
        
        let mut nodes: Vec<gsk::RenderNode> = Vec::with_capacity(buffer.len() + 10);

        // Frame background
        let bg_rect = graphene::Rect::new(0.0, 0.0, buffer.width, buffer.height);
        let bg_color = color_to_gdk(&buffer.background);
        nodes.push(gsk::ColorNode::new(&bg_color, &bg_rect).upcast());
        debug!("Added frame background node");

        // Collect glyph data and partition into regular vs overlay
        let glyphs: Vec<_> = buffer.glyphs.iter().cloned().collect();
        let (regular_glyphs, overlay_glyphs): (Vec<_>, Vec<_>) = glyphs.into_iter().partition(|g| !g.is_overlay());

        // Process backgrounds FIRST (from regular glyphs only)
        let mut bg_count = 0;
        for glyph in &regular_glyphs {
            if let FrameGlyph::Background { bounds, color } = glyph {
                bg_count += 1;
                let rect = graphene::Rect::new(bounds.x, bounds.y, bounds.width, bounds.height);
                let gdk_color = color_to_gdk(color);
                nodes.push(gsk::ColorNode::new(&gdk_color, &rect).upcast());
            }
        }
        debug!("Added {} background(s) FIRST", bg_count);

        // Process regular glyphs (excluding backgrounds, which were handled above)
        let mut char_count = 0;
        for glyph in regular_glyphs {
            self.render_glyph(&glyph, &mut nodes, &mut video_cache, &mut char_count, false);
        }

        // Process overlay glyphs LAST so they render on top
        for glyph in &overlay_glyphs {
            if let FrameGlyph::Background { bounds, color } = glyph {
                let rect = graphene::Rect::new(bounds.x, bounds.y, bounds.width, bounds.height);
                let gdk_color = color_to_gdk(color);
                nodes.push(gsk::ColorNode::new(&gdk_color, &rect).upcast());
            }
        }
        for glyph in overlay_glyphs {
            self.render_glyph(&glyph, &mut nodes, &mut video_cache, &mut char_count, true);
        }

        debug!("Processed {} chars, {} backgrounds, total {} nodes", char_count, bg_count, nodes.len());

        if nodes.is_empty() {
            debug!("build_render_node: returning None (empty nodes)");
            None
        } else {
            debug!("build_render_node: returning ContainerNode with {} nodes", nodes.len());
            Some(gsk::ContainerNode::new(&nodes).upcast())
        }
    }

    /// Render a single glyph to the nodes list
    fn render_glyph(
        &mut self,
        glyph: &FrameGlyph,
        nodes: &mut Vec<gsk::RenderNode>,
        video_cache: &mut Option<&mut VideoCache>,
        char_count: &mut usize,
        _is_overlay_pass: bool,
    ) {
        match glyph {
            FrameGlyph::Background { .. } => {
                // Already processed in background pass
            }

            FrameGlyph::Char {
                char,
                x,
                y,
                width,
                height,
                ascent,
                fg,
                bg,
                face_id,
                ..
            } => {
                *char_count += 1;
                // Draw char background if specified
                if let Some(bg_color) = bg {
                    let rect = graphene::Rect::new(*x, *y, *width, *height);
                    nodes.push(gsk::ColorNode::new(&color_to_gdk(bg_color), &rect).upcast());
                }

                // Skip whitespace - no need to render
                if *char == ' ' || *char == '\t' || *char == '\n' {
                    return;
                }

                // Get or rasterize glyph
                if let Some(cached) = self.get_or_rasterize_glyph(*char, *face_id, fg) {
                    // Position glyph using bearing
                    let glyph_x = x + cached.bearing_x;
                    let glyph_y = y + ascent - cached.bearing_y;

                    let rect = graphene::Rect::new(
                        glyph_x,
                        glyph_y,
                        cached.width as f32,
                        cached.height as f32,
                    );

                    // Create texture node
                    let texture_node = gsk::TextureNode::new(&cached.texture, &rect);
                    nodes.push(texture_node.upcast());
                }
            }

            FrameGlyph::Stretch {
                x,
                y,
                width,
                height,
                bg,
                ..
            } => {
                let rect = graphene::Rect::new(*x, *y, *width, *height);
                nodes.push(gsk::ColorNode::new(&color_to_gdk(bg), &rect).upcast());
            }

            FrameGlyph::Cursor {
                window_id: _,
                x,
                y,
                width,
                height,
                style,
                color,
            } => {
                let cursor_color = color_to_gdk(color);
                match style {
                    0 => {
                        // Box (filled)
                        let rect = graphene::Rect::new(*x, *y, *width, *height);
                        nodes.push(gsk::ColorNode::new(&cursor_color, &rect).upcast());
                    }
                    1 => {
                        // Bar (vertical line)
                        let rect = graphene::Rect::new(*x, *y, 2.0, *height);
                        nodes.push(gsk::ColorNode::new(&cursor_color, &rect).upcast());
                    }
                    2 => {
                        // Underline
                        let rect = graphene::Rect::new(*x, *y + *height - 2.0, *width, 2.0);
                        nodes.push(gsk::ColorNode::new(&cursor_color, &rect).upcast());
                    }
                    3 => {
                        // Hollow box (outline)
                        let thickness = 1.0;
                        let top = graphene::Rect::new(*x, *y, *width, thickness);
                        nodes.push(gsk::ColorNode::new(&cursor_color, &top).upcast());
                        let bottom = graphene::Rect::new(*x, *y + *height - thickness, *width, thickness);
                        nodes.push(gsk::ColorNode::new(&cursor_color, &bottom).upcast());
                        let left = graphene::Rect::new(*x, *y, thickness, *height);
                        nodes.push(gsk::ColorNode::new(&cursor_color, &left).upcast());
                        let right = graphene::Rect::new(*x + *width - thickness, *y, thickness, *height);
                        nodes.push(gsk::ColorNode::new(&cursor_color, &right).upcast());
                    }
                    _ => {}
                }
            }

            FrameGlyph::Border {
                x,
                y,
                width,
                height,
                color,
            } => {
                let rect = graphene::Rect::new(*x, *y, *width, *height);
                nodes.push(gsk::ColorNode::new(&color_to_gdk(color), &rect).upcast());
            }

            FrameGlyph::Image {
                image_id: _,
                x,
                y,
                width,
                height,
            } => {
                // TODO: Look up image from cache and render
                let rect = graphene::Rect::new(*x, *y, *width, *height);
                let placeholder = gdk::RGBA::new(0.3, 0.3, 0.4, 1.0);
                nodes.push(gsk::ColorNode::new(&placeholder, &rect).upcast());
            }

            FrameGlyph::Video {
                video_id,
                x,
                y,
                width,
                height,
            } => {
                let rect = graphene::Rect::new(*x, *y, *width, *height);
                let mut rendered = false;
                
                // Try to render video from cache (update() already called at start of frame)
                if let Some(ref mut cache) = video_cache {
                    if let Some(player) = cache.get_mut(*video_id) {
                        if let Some(paintable) = player.get_paintable() {
                            let pw = paintable.intrinsic_width();
                            let ph = paintable.intrinsic_height();
                            
                            if pw > 0 && ph > 0 {
                                // Calculate dimensions that preserve aspect ratio
                                let video_aspect = pw as f32 / ph as f32;
                                let target_aspect = width / height;
                                
                                let (render_w, render_h, offset_x, offset_y) = if video_aspect > target_aspect {
                                    // Video is wider - fit to width, center vertically
                                    let h = width / video_aspect;
                                    (*width, h, 0.0, (*height - h) / 2.0)
                                } else {
                                    // Video is taller - fit to height, center horizontally
                                    let w = height * video_aspect;
                                    (w, *height, (*width - w) / 2.0, 0.0)
                                };
                                
                                // Use snapshot to render paintable into a node
                                let snapshot = gtk4::Snapshot::new();
                                snapshot.translate(&graphene::Point::new(*x + offset_x, *y + offset_y));
                                paintable.snapshot(
                                    snapshot.upcast_ref::<gdk::Snapshot>(),
                                    render_w as f64,
                                    render_h as f64,
                                );
                                if let Some(node) = snapshot.to_node() {
                                    let clipped = gsk::ClipNode::new(&node, &rect);
                                    nodes.push(clipped.upcast());
                                    rendered = true;
                                    // Count this frame for FPS tracking
                                    player.count_frame();
                                }
                            }
                        }
                    }
                }
                
                // Placeholder if video not available
                if !rendered {
                    let placeholder = gdk::RGBA::new(0.2, 0.2, 0.3, 1.0);
                    nodes.push(gsk::ColorNode::new(&placeholder, &rect).upcast());
                }
            }

            FrameGlyph::WebKit {
                webkit_id: _,
                x,
                y,
                width,
                height,
            } => {
                // TODO: Look up webkit from cache and render
                let rect = graphene::Rect::new(*x, *y, *width, *height);
                let placeholder = gdk::RGBA::new(0.1, 0.1, 0.2, 1.0);
                nodes.push(gsk::ColorNode::new(&placeholder, &rect).upcast());
            }
        }
    }
}

/// Convert our Color to GDK RGBA
fn color_to_gdk(color: &Color) -> gdk::RGBA {
    // Color fields are already in 0.0-1.0 range
    gdk::RGBA::new(color.r, color.g, color.b, color.a)
}
